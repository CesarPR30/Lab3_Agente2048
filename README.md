# ğŸ§  Laboratorio 3 â€“ Agente 2048

ImplementaciÃ³n de un agente para el juego **2048**.

El objetivo del laboratorio es diseÃ±ar una polÃ­tica que maximice el desempeÃ±o promedio del agente bajo seeds fijas.

---

## ğŸ“Œ Requerimientos

- Python 3.10+
- numpy < 2
- matplotlib


## â–¶ï¸ CÃ³mo ejecutar

### ğŸ® Modo manual
Permite jugar 2048 con teclado.

```bash
python run_2048.py --mode manual
```

---

### ğŸ¤– Modo agente

Asumiendo que la soluciÃ³n estÃ¡ en `solucion.py`:

```bash
python run_2048.py --mode agent --agent-module solucion --agent-class Agent --episodes 50
```

---

## ğŸ“Š EvaluaciÃ³n oficial

El laboratorio usa `evaluation.py`:

```python
final_score = 1000 * mean_log_score \
            + 30 * mean_log2_max_tile \
            + 10 * median_log_score \
            - 2 * mean_log_steps
```

Donde:

- `mean_log_score = mean(log(1 + score))`
- `mean_log2_max_tile = mean(log2(max_tile))`
- `mean_log_steps = mean(log(1 + steps))`

Para evaluaciÃ³n local:

```python
from evaluation import evaluate_agent_scalar
from solucion import Agent

seeds = [0] #list(range(50))
agent = Agent()
print(evaluate_agent_scalar(agent, seeds))
```

---

## ğŸš« Uso de VRAM

El agente estÃ¡ implementado Ãºnicamente con **NumPy (CPU)**.

No utiliza GPU ni frameworks como PyTorch o TensorFlow.

Consumo de VRAM: **~0 MB**  
Cumple con la restricciÃ³n de mÃ¡ximo 5GB en inferencia.

---

## ğŸ“‚ Estructura del proyecto

```
.
â”œâ”€â”€ solucion.py          # ImplementaciÃ³n del agente
â”œâ”€â”€ run_2048.py          # Runner (manual y agente)
â”œâ”€â”€ evaluation.py        # EvaluaciÃ³n oficial
â”œâ”€â”€ eval_local.py        # EvaluaciÃ³n local
â”œâ”€â”€ game_2048.py         # LÃ³gica del juego
â”œâ”€â”€ viz_2048.py          # Renderizado
```

---

## ğŸ¯ Objetivo

Maximizar `final_score` en mÃºltiples seeds fijas bajo restricciones de eficiencia.

---

## ğŸ‘¤ Grupo - OptimusPrime:

* CÃ©sar Eduardo Pajuelo Reyes
* Gonzalo Alonso Rodriguez Gutierrez
